# neo4j authentication
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=change-me!

# neo4j graph database URI used by the backend to connect to neo4j
# use "bolt://localhost" when the backend and neo4j are both running locally outside Docker
# use "bolt://host.docker.internal" when the backend is running within Docker but neo4j is running locally (outside Docker)
# URI will be set to the neo4j container's host if using Docker Compose
NEO4J_URI=bolt://localhost:7687

# port configuration is optional
# used with Docker Compose to expose neo4j on non-default ports
NEO4J_HTTP_PORT=7474
NEO4J_BOLT_PORT=7687

# files location
FILES_DIRECTORY=files

# redis cache configuration
REDIS_HOST="localhost"

# backend LLM properties
MISTRAL_KEY=my-api-key

# OpenAI LLM properties
OPENAI_KEY=my-openai-api-key

# frontend host - used to configure backend CORS
FRONTEND_URL=http://localhost:8650

# what backend URL should be used by frontend API requests
BACKEND_URL=http://localhost:8250

# websockets url to connect to backend websocket endpoint
WS_URL=ws://localhost:8250/ws

# llm
ANSWER_AGENT_LLM="mistral"
INTENT_AGENT_LLM="openai"
REPORT_AGENT_LLM="openai"
MATERIALITY_AGENT_LLM="openai"
VALIDATOR_AGENT_LLM="openai"
DATASTORE_AGENT_LLM="openai"
WEB_AGENT_LLM="openai"
CHART_GENERATOR_LLM="openai"
ROUTER_LLM="openai"
FILE_AGENT_LLM="openai"
SUGGESTIONS_LLM="openai"
DYNAMIC_KNOWLEDGE_GRAPH_LLM="openai"


# model
ANSWER_AGENT_MODEL="mistral-large-latest"
INTENT_AGENT_MODEL="gpt-4o"
REPORT_AGENT_MODEL="gpt-4o"
MATERIALITY_AGENT_MODEL="gpt-4o"
VALIDATOR_AGENT_MODEL="gpt-4o-mini"
DATASTORE_AGENT_MODEL="gpt-4o"
WEB_AGENT_MODEL="gpt-4o"
CHART_GENERATOR_MODEL="gpt-4o-mini"
ROUTER_MODEL="gpt-4o"
FILE_AGENT_MODEL="gpt-4o"
SUGGESTIONS_MODEL="gpt-4o-mini"
DYNAMIC_KNOWLEDGE_GRAPH_MODEL="gpt-4o"

# Set this to restrict which chat agents are available for solving questions.
# ALLOWED_CHAT_AGENTS="DatastoreAgent,WebAgent,MaterialityAgent,FileAgent"