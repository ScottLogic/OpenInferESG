import json
import logging
import os

from dotenv import load_dotenv
from src.llm.llm import LLM
from src.utils.graph_db_utils import execute_query
from src.prompts import PromptEngine
from datetime import datetime
from src.utils import to_json
from src.utils.log_publisher import LogPrefix, publish_log_info
from src.agents.agent import chat_agent
from src.agents.base_chat_agent import BaseChatAgent
from src.agents.tool import tool, Parameter, ToolActionSuccess, ToolActionFailure
from src.utils.semantic_layer_builder import get_semantic_layer, semantic_layer_ready

logger = logging.getLogger(__name__)

engine = PromptEngine()

cache = {}


async def generate_cypher_query_core(
    question_intent, operation, question_params, aggregation, sort_order, timeframe, llm: LLM, model
) -> ToolActionSuccess | ToolActionFailure:
    await semantic_layer_ready.wait()
    details_to_create_cypher_query = engine.load_prompt(
        "details-to-create-cypher-query",
        question_intent=question_intent,
        operation=operation,
        question_params=question_params,
        aggregation=aggregation,
        sort_order=sort_order,
        timeframe=timeframe,
    )
    try:
        graph_schema = await get_semantic_layer_cache(llm, model)
        graph_schema = json.dumps(graph_schema, separators=(",", ":"))

        generate_cypher_query_prompt = engine.load_prompt(
            "generate-cypher-query", graph_schema=graph_schema, current_date=datetime.now()
        )

        llm_query = await llm.chat(
            model, generate_cypher_query_prompt, details_to_create_cypher_query, agent="datastore",return_json=True
        )
        json_query = to_json(llm_query)
        await publish_log_info(LogPrefix.USER, f"Cypher generated by the LLM: {llm_query}", __name__)
        if json_query["query"] == "None":
            return ToolActionFailure("No database query", True)
        response = execute_query(json_query["query"])
        await publish_log_info(LogPrefix.USER, f"Database response: {response}", __name__)
    except Exception as e:
        logger.error(f"Error during data retrieval: {e}")
        raise
    return ToolActionSuccess(response)


@tool(
    name="generate cypher query",
    description="Generate Cypher query if the category is data driven, based on the operation to be performed",
    parameters={
        "question_intent": Parameter(
            type="string",
            description="The intent the question will be based on",
        ),
        "operation": Parameter(
            type="string",
            description="The operation the cypher query will have to perform",
        ),
        "question_params": Parameter(
            type="string",
            description="The specific parameters required for the question to be answered with the question_intent"
            "or none if no params required"
        ),
        "aggregation": Parameter(
            type="string",
            description="Any aggregation that is required to answer the question or none if no aggregation is needed",
        ),
        "sort_order": Parameter(
            type="string",
            description="The order a list should be sorted in or none if no sort_order is needed",
        ),
        "timeframe": Parameter(
            type="string",
            description="string of the timeframe to be considered or none if no timeframe is needed",
        ),
    },
)
async def generate_cypher(
    question_intent, operation, question_params, aggregation, sort_order, timeframe, llm: LLM, model
) -> ToolActionSuccess | ToolActionFailure:
    return await generate_cypher_query_core(
        question_intent, operation, question_params, aggregation, sort_order, timeframe, llm, model
    )


async def get_semantic_layer_cache(llm, model):
    global cache
    if not cache:
        graph_schema = await get_semantic_layer(llm, model)
        cache = graph_schema
        return cache
    else:
        return cache

async def initialize_semantic_layer():
    try:
        load_dotenv()
        llm_name = os.getenv("DATASTORE_AGENT_LLM")
        model_name = os.getenv("DATASTORE_AGENT_MODEL")

        llm_instances = LLM.get_instances()
        llm = llm_instances.get(llm_name)

        await get_semantic_layer_cache(llm, model_name)
    except Exception as e:
        logger.exception(e)


@chat_agent(
    name="DatastoreAgent",
    description="This agent is responsible for answering questions about the bloomberg.csv dataset. This includes "
                "retrieving ESG scores, financial metrics, and other bloomberg-specific information. It interacts with "
                "the graph database to extract, process, and return ESG-related information from various sources, such "
                "as company sustainability reports or fund portfolios. This agent can not answer questions that do not "
                "specifically reference the bloomberg.csv dataset.",
    tools=[generate_cypher],
)
class DatastoreAgent(BaseChatAgent):
    pass
