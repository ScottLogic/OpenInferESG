# LM Studio Configuration
LMSTUDIO_URL=http://host.docker.internal:1234
LMSTUDIO_MODEL=local-model

# Other LLM providers (if needed)
# MISTRAL_URL=https://api.mistral.ai
# MISTRAL_KEY=your_api_key
# OPENAI_KEY=your_api_key

# LM Studio properties - for local running LLM models
# Use host.docker.internal instead of 127.0.0.1 when running in Docker
# The base URL without the /v1 path (this will be added in the code)
LMSTUDIO_URL=http://host.docker.internal:1234
LMSTUDIO_MODEL=liquid/lfm2-1.2b

# Neo4j Configuration
NEO4J_URI=bolt://neo4j:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password

# Redis Configuration
REDIS_HOST=redis

# Frontend URL
FRONTEND_URL=http://localhost:8650

# Agent LLM configurations
ANSWER_AGENT_LLM=lmstudio
INTENT_AGENT_LLM=lmstudio
REPORT_AGENT_LLM=lmstudio
MATERIALITY_AGENT_LLM=lmstudio
VALIDATOR_AGENT_LLM=lmstudio
DATASTORE_AGENT_LLM=lmstudio
WEB_AGENT_LLM=lmstudio
CHART_GENERATOR_LLM=lmstudio
ROUTER_LLM=lmstudio
SUGGESTIONS_LLM=lmstudio
DYNAMIC_KNOWLEDGE_GRAPH_LLM=lmstudio
FILE_AGENT_LLM=lmstudio

# Agent Model configurations
ANSWER_AGENT_MODEL=local-model
INTENT_AGENT_MODEL=local-model
REPORT_AGENT_MODEL=local-model
MATERIALITY_AGENT_MODEL=local-model
VALIDATOR_AGENT_MODEL=local-model
DATASTORE_AGENT_MODEL=local-model
WEB_AGENT_MODEL=local-model
CHART_GENERATOR_MODEL=local-model
ROUTER_MODEL=local-model
SUGGESTIONS_MODEL=local-model
DYNAMIC_KNOWLEDGE_GRAPH_MODEL=local-model
FILE_AGENT_MODEL=local-model
